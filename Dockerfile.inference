# Dockerfile.inference

# Utiliser une image Python légère
FROM python:3.9-slim

# Définir le répertoire de travail
WORKDIR /app

# Copier le fichier d'inférence
COPY inference.py /app/inference.py

# Copier le fichier requirements.txt
COPY requirements.txt /app/requirements.txt

# Installer les dépendances requises
RUN pip install --no-cache-dir -r requirements.txt

# Exposer le port utilisé par FastAPI
EXPOSE 8000

# Commande pour lancer le serveur FastAPI pour l'inférence
CMD ["uvicorn", "inference:app", "--host", "0.0.0.0", "--port", "8000"]
